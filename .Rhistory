delim = "\t",
col_names = FALSE)
loss <- as.numeric(loss)
loss<-(t(t(loss)))
loss <- as.data.frame(loss)
loss <- loss[2:101,]
loss <- as.data.frame(loss)
l <- ggplot(data = loss, aes(y= loss, x=seq(from = 1, to = 100), group=1)) +
geom_line(color="blue", size=0.5)+
geom_point(color="blue") +
#geom_text(data = loss,label=loss$V1)+
labs(x = "Epochs", y = "Loss")+
#labs(x = "Epochs", y = "Loss", title = "Spanish Original 30 loss")+
scale_x_continuous(breaks=seq(from = 0, to = 100, by = 10))+
geom_vline(xintercept=13, color = 'darkgrey',size = 1.1, linetype=2)+
theme_set(new)
f1 <- read_delim(paste( which_model , "f1.txt" , sep = "_"),
delim = "\t",
col_names = FALSE)
f1 <- as.numeric(f1)
f1<-(t(t(f1)))
f1 <- as.data.frame(f1)
f1[is.na(f1)] <- 0
f1 <- f1[2:101,]
f1 <- as.data.frame(f1)
f1p<- ggplot(data = f1, aes(y= f1, x=seq(from = 1, to = 100)),color="red") +
geom_line(color="blue", size=1)+
geom_point(color="blue") +
scale_x_continuous(breaks=seq(from = 0, to = 100, by = 10))+
scale_y_continuous(breaks=seq(from = 0, to = 1, by = 0.1))+
labs(x = "Epochs", y = "F1 - Score")+
geom_vline(xintercept=13, color = 'darkgrey',size = 1.1, linetype=2)+
#labs(x = "Epochs", y = "F1 - Score", title = "Spanish Original 30 F1")
theme_set(new)
View(f1)
View(loss)
l
f1
f1p
which_model = "/Users/Cristhian/Documents/ThesisNER/StatisticalNER/MultiCCA_German_30"
#-----------------------Loss-----------------
loss <- read_delim(paste( which_model , "loss.txt" , sep = "_") ,
delim = "\t",
col_names = FALSE)
loss <- as.numeric(loss)
loss<-(t(t(loss)))
loss <- as.data.frame(loss)
loss <- loss[2:101,]
loss <- as.data.frame(loss)
l <- ggplot(data = loss, aes(y= loss, x=seq(from = 1, to = 100), group=1)) +
geom_line(color="blue", size=0.5)+
geom_point(color="blue") +
#geom_text(data = loss,label=loss$V1)+
labs(x = "Epochs", y = "Loss")+
#labs(x = "Epochs", y = "Loss", title = "Spanish Original 30 loss")+
scale_x_continuous(breaks=seq(from = 0, to = 100, by = 10))+
geom_vline(xintercept=13, color = 'darkgrey',size = 1.1, linetype=2)+
theme_set(new)
f1 <- read_delim(paste( which_model , "f1.txt" , sep = "_"),
delim = "\t",
col_names = FALSE)
f1 <- as.numeric(f1)
f1<-(t(t(f1)))
f1 <- as.data.frame(f1)
f1[is.na(f1)] <- 0
f1 <- f1[2:101,]
f1 <- as.data.frame(f1)
f1p<- ggplot(data = f1, aes(y= f1, x=seq(from = 1, to = 100)),color="red") +
geom_line(color="blue", size=1)+
geom_point(color="blue") +
scale_x_continuous(breaks=seq(from = 0, to = 100, by = 10))+
scale_y_continuous(breaks=seq(from = 0, to = 1, by = 0.1))+
labs(x = "Epochs", y = "F1 - Score")+
geom_vline(xintercept=13, color = 'darkgrey',size = 1.1, linetype=2)+
#labs(x = "Epochs", y = "F1 - Score", title = "Spanish Original 30 F1")
theme_set(new)
View(f1)
View(loss)
f1p
which_model = "/Users/Cristhian/Documents/ThesisNER/StatisticalNER/MultiCCA_All_30"
loss <- read_delim(paste( which_model , "loss.txt" , sep = "_") ,
delim = "\t",
col_names = FALSE)
loss <- as.numeric(loss)
loss<-(t(t(loss)))
loss <- as.data.frame(loss)
loss <- loss[2:101,]
loss <- as.data.frame(loss)
l <- ggplot(data = loss, aes(y= loss, x=seq(from = 1, to = 100), group=1)) +
geom_line(color="blue", size=0.5)+
geom_point(color="blue") +
#geom_text(data = loss,label=loss$V1)+
labs(x = "Epochs", y = "Loss")+
#labs(x = "Epochs", y = "Loss", title = "Spanish Original 30 loss")+
scale_x_continuous(breaks=seq(from = 0, to = 100, by = 10))+
geom_vline(xintercept=13, color = 'darkgrey',size = 1.1, linetype=2)+
theme_set(new)
f1 <- read_delim(paste( which_model , "f1.txt" , sep = "_"),
delim = "\t",
col_names = FALSE)
f1 <- as.numeric(f1)
f1<-(t(t(f1)))
f1 <- as.data.frame(f1)
f1[is.na(f1)] <- 0
f1 <- f1[2:101,]
f1 <- as.data.frame(f1)
f1p<- ggplot(data = f1, aes(y= f1, x=seq(from = 1, to = 100)),color="red") +
geom_line(color="blue", size=1)+
geom_point(color="blue") +
scale_x_continuous(breaks=seq(from = 0, to = 100, by = 10))+
scale_y_continuous(breaks=seq(from = 0, to = 1, by = 0.1))+
labs(x = "Epochs", y = "F1 - Score")+
geom_vline(xintercept=13, color = 'darkgrey',size = 1.1, linetype=2)+
#labs(x = "Epochs", y = "F1 - Score", title = "Spanish Original 30 F1")
theme_set(new)
f1p
l
View(f1)
View(loss)
packages <- c(
"tidyverse",
"jsonlite",
"abind",
"gridExtra",
"pracma",
"tokenizers",
"stringr",
"keras"
)
install.packages(packages)
install.packages(packages)
install.packages(packages)
install.packages(packages)
install.packages(packages)
install.packages(packages)
install.packages(packages)
library(keras)
restart()
library(keras)
packages <- c(
"tidyverse",
"jsonlite",
"abind",
"gridExtra",
"pracma",
"tokenizers",
"stringr",
"keras"
)
install.packages(packages)
library(keras)
library(keras)
mnist <- dataset_mnist()
x_train <- mnist$train$x
mnist <- dataset_mnist()
devtools::install_github("rstudio/keras")
install.packages("devtools")
library(devtools)
devtools::install_github("rstudio/keras")
library(keras)
mnist <- dataset_mnist()
dataset_mnist()
library(keras)
library(keras)
install.packages("reticulate")
install.packages("reticulate")
library(keras)
devtools::install_github("rstudio/reticulate")
library(keras)
library(keras)
library(reticulate)
library(keras)
dataset_mnist()
library(keras)
dataset_mnist()
library(keras)
library(keras)
library(tidyverse)
library(jsonlite)
library(abind)
library(gridExtra)
library(pracma)
source('utils.R')
ships_json <- fromJSON("shipsnet.json")[1:2]
ships_json <- fromJSON("shipsnet.json")[1:2]
names(ships_json)
dim(ships_json$data)
length(ships_json$labels)
sample_image <- ships_json$data[1,]
r <- matrix(sample_image[1:6400], 80, 80, byrow = TRUE) / 255
g <- matrix(sample_image[6401:12800], 80, 80, byrow = TRUE) / 255
b <- matrix(sample_image[12801:19200], 80, 80, byrow = TRUE) / 255
sample_image <- array(c(?, ?, ?), dim = c(80, 80, 3))
sample_image <- array(c(r, g, b), dim = c(80, 80, 3))
plot_sample_image(sample_image, show_layers = TRUE)
sample_image_rot90 <- array(c(rot90(r, 1), c(rot90(g, 1), c(rot90(b, 1)), dim = c(80, 80, 3))
sample_image_rot90 <- array(c(rot90(r, 1), rot90(g, 1), rot90(b, 1)), dim = c(80, 80, 3))
sample_image_rot180 <- array(c(rot90(r, 1), rot90(g, 1), rot90(b, 1)), dim = c(80, 80, 3))
sample_image_rot270 <- array(c(rot90(r, 1), rot90(g, 1), rot90(b, 1)), dim = c(80, 80, 3))
grid.arrange(plot_sample_image(sample_image),
plot_sample_image(sample_image_rot90),
plot_sample_image(sample_image_rot180),
plot_sample_image(sample_image_rot270),
ncol = 2, nrow = 2)
ships_data <- ships_json$data %>% apply(., 1, function(x) {
r <- matrix(x[1:6400], 80, 80, byrow = TRUE) / 255
g <- matrix(x[6401:12800], 80, 80, byrow = TRUE) / 255
b <- matrix(x[12801:19200], 80, 80, byrow = TRUE) / 255
list(array(c(r,g,b), dim = c(80, 80, 3)),
array(c(rot90(r, 1), rot90(g, 1), rot90(b, 1)), dim = c(80, 80, 3)),
array(c(rot90(r, 2), rot90(g, 2), rot90(b, 2)), dim = c(80, 80, 3)),
array(c(rot90(r, 3), rot90(g, 3), rot90(b, 3)), dim = c(80, 80, 3)))
}) %>% do.call(c, .) %>% abind(., along = 4) %>% aperm(c(4, 1, 2, 3))
ships_labels <- ships_json$labels %>% map(~ rep(.x, 4)) %>%
unlist() %>% to_categorical(2)
model1 <- keras_model_sequential()
library(keras)
library(tidyverse)
library(jsonlite)
library(abind)
library(gridExtra)
library(pracma)
source('utils.R')
ships_json <- fromJSON("shipsnet.json")[1:2]
names(ships_json)
dim(ships_json$data)
length(ships_json$labels)
sample_image <- ships_json$data[1,]
dim()
dim(sample_image)
dim(sample_image)
sample_image <- ships_json$data[1,]
sample_image <- as.numeric(ships_json$data[1,])
dim(sample_image)
names(ships_json)
dim(ships_json$data)
length(ships_json$labels)
ships_json$data[1,]
sample_image_ <- ships_json$data[1,]
dim(sample_image_)
sample_image_ = ships_json$data[1,]
sample_image_
sample_image_
sample_image_
dim(sample_image)
dim(sample_image_)
dim(sample_image)
sample_image
r <- matrix(sample_image[1:6400], 80, 80, byrow = TRUE) / 255
g <- matrix(sample_image[64001:12800], 80, 80, byrow = TRUE) / 255
r <- matrix(sample_image[1:6400], 80, 80, byrow = TRUE) / 255
g <- matrix(sample_image[6401:12800], 80, 80, byrow = TRUE) / 255
b <- matrix(sample_image[12801:19200], 80, 80, byrow = TRUE) / 255
sample_image <- array(c(r, g, b), dim = c(80, 80, 3))
plot_sample_image(sample_image, show_layers = TRUE)
sample_image_rot90 <- array(c(rot90(r, 1), c(rot90(g, 1), c(rot90(b, 1)), dim = c(80, 80, 3))
sample_image_rot90 <- array(c(rot90(r, 1), rot90(g, 1), rot90(b, 1)), dim = c(80, 80, 3))
sample_image_rot90 <- array(c(rot90(r, 1), rot90(g, 1), rot90(b, 1)), dim = c(80, 80, 3))
sample_image_rot180 <- array(c(rot90(r, 1), rot90(g, 1), rot90(b, 1)), dim = c(80, 80, 3))
sample_image_rot270 <- array(c(rot90(r, 1), rot90(g, 1), rot90(b, 1)), dim = c(80, 80, 3))
grid.arrange(plot_sample_image(sample_image),
plot_sample_image(sample_image_rot90),
plot_sample_image(sample_image_rot180),
plot_sample_image(sample_image_rot270),
ncol = 2, nrow = 2)
ships_data <- ships_json$data %>% apply(., 1, function(x) {
r <- matrix(x[1:6400], 80, 80, byrow = TRUE) / 255
g <- matrix(x[6401:12800], 80, 80, byrow = TRUE) / 255
b <- matrix(x[12801:19200], 80, 80, byrow = TRUE) / 255
list(array(c(r,g,b), dim = c(80, 80, 3)),
array(c(rot90(r, 1), rot90(g, 1), rot90(b, 1)), dim = c(80, 80, 3)),
array(c(rot90(r, 2), rot90(g, 2), rot90(b, 2)), dim = c(80, 80, 3)),
array(c(rot90(r, 3), rot90(g, 3), rot90(b, 3)), dim = c(80, 80, 3)))
}) %>% do.call(c, .) %>% abind(., along = 4) %>% aperm(c(4, 1, 2, 3))
ships_labels <- ships_json$labels %>% map(~ rep(.x, 4)) %>%
unlist() %>% to_categorical(2)
library(tidyverse)
library(reshape2)
library(ggplot2)
library(plotly)
library(rpivotTable)
library(keras)
library(lubridate)
library(dplyr)
library(forecast)
library(xts)
install_keras()
devtools::install_github("rstudio/keras")
model <- keras_model_sequential()
model %>%
layer_lstm(units            = 50,
input_shape      = c(tsteps, 1),
batch_size       = batch_size,
return_sequences = TRUE,
stateful         = TRUE) %>%
layer_lstm(units            = 50,
return_sequences = FALSE,
stateful         = TRUE) %>%
layer_dense(units = 1)
model %>%
compile(loss = 'mae', optimizer = 'adam')
model
model <- keras_model_sequential()
install_keras()
library(tidyverse)
library(reshape2)
library(ggplot2)
library(plotly)
library(rpivotTable)
library(keras)
library(lubridate)
library(dplyr)
library(forecast)
library(xts)
install_keras()
library(tidyverse)
library(reshape2)
library(ggplot2)
library(plotly)
library(rpivotTable)
library(keras)
library(lubridate)
library(dplyr)
library(forecast)
library(xts)
install_keras()
install_keras()
reticulate::conda_remove()
reticulate::conda_remove(envname = "py3tf")
install_keras()
conda_remove(“r-tensorflow”)
conda_remove('r-tensorflow')
library(reticulate)
conda_remove('r-tensorflow')
install_keras()
library(tidyverse)
library(reshape2)
library(ggplot2)
library(plotly)
library(rpivotTable)
library(keras)
library(lubridate)
library(dplyr)
library(forecast)
library(xts)
packs <- c('tidyverse'
,'reshape2'
,'ggplot2'
,'plotly'
,'rpivotTable'
,'keras'
,'lubridate'
,'dplyr'
,'forecast'
,'xts')
packs
install.packages(packs)
library(tidyverse)
library(reshape2)
library(ggplot2)
library(plotly)
library(rpivotTable)
library(keras)
library(lubridate)
library(dplyr)
library(forecast)
library(xts)
library(tidyverse)
library(reshape2)
library(ggplot2)
library(plotly)
library(rpivotTable)
library(keras)
library(lubridate)
library(dplyr)
library(forecast)
library(xts)
install.packages(tidyverse)
install.packages('tidyverse')
install.packages('tidyverse')
library(tidyverse)
library(tidyverse, dependencies = TRUE)
install.packages(tidyverse, dependencies = TRUE)
install.packages('tidyverse', dependencies = TRUE)
library(tidyverse)
library(tidyverse)
library(reshape2)
library(ggplot2)
library(plotly)
library(rpivotTable)
library(keras)
library(lubridate)
library(dplyr)
library(forecast)
library(xts)
setwd("/Users/Cristhian/Documents/Zalando/")
data <- read.csv("Sales.csv", header = TRUE, sep = ",")
dictDates <- as.data.frame(ymd("2016-12-01") + days(0:395))
dictDates <- as.data.frame(ymd("2016-12-01") + weeks(0:57))
lcl <- 0:5
ModelsByClst <- function(custDict, data){
clModels <- list()
for(i in 0:5){
toTs <- custDict %>%
filter(cluster == i) %>%
left_join(data) %>%
group_by(date = cut(as.Date(date) ,'week')) %>%
summarise(sales = sum(sales), count_clients = n_distinct(customer) )%>%
mutate(avgSales = sales/count_clients )%>%
filter(as.Date(date) < as.Date('2017-12-01'))
clTs <- xts(toTs$avgSales,as.Date(toTs$date))
fit <- auto.arima(clTs)
print(i)
print(fit)
clModels[[i+1]] <- fit
}
return(clModels)
}
mods <- ModelsByClst(custDict,data)
gs1<- select(GroupSales1,sales,count)
gs1$sales<-(gs1$sales-mean(gs1$sales))/ sd(gs1$sales)
gs1$count<-(gs1$count-mean(gs1$count))/ sd(gs1$count)
km1 <- kmeans(gs1,5)
ggplot(GroupSales1, aes( x=sales, y=count, color=km1$cluster))+
geom_point()+
theme_minimal()
GroupSales1<- GroupSales1 %>% add_column(cluster = km1$cluster)
gs1Dict <- GroupSales1 %>% select(customer,cluster)
custDict <- data %>%
group_by(customer) %>%
summarise(count = n())%>%
select(customer)
GroupSales <- data %>%
group_by(customer)%>%
summarise(sales = sum(sales), count = n())%>%
mutate(limitSales = ifelse((sales-mean(sales))/sd(sales)<=2.5, 1, 0))
sum(GroupSales$sales)
GroupSales1 <- GroupSales %>%
filter(limitSales==1)
length(GroupSales1$customer)
summarise(GroupSales1, n_distinct(customer))
sum(GroupSales1$sales)/sum(GroupSales$sales)
GroupSales0 <- GroupSales %>%
filter(limitSales==0)
length(GroupSales0$customer)
summarise(GroupSales0, n_distinct(customer))
sum(GroupSales0$sales)/sum(GroupSales$sales)
km1 <- kmeans(gs1,5)
ggplot(GroupSales1, aes( x=sales, y=count, color=km1$cluster))+
geom_point()+
theme_minimal()
gs1<- select(GroupSales1,sales,count)
km1 <- kmeans(gs1,5)
ggplot(GroupSales1, aes( x=sales, y=count, color=km1$cluster))+
geom_point()+
theme_minimal()
GroupSales1<- GroupSales1 %>% add_column(cluster = km1$cluster)
gs1Dict <- GroupSales1 %>% select(customer,cluster)
custDict <- data %>%
group_by(customer) %>%
summarise(count = n())%>%
select(customer)
custDict <- left_join( custDict , gs1Dict)
custDict$cluster <- ifelse(is.na(custDict$cluster),0,custDict$cluster)
lcl <- 0:5
ModelsByClst <- function(custDict, data){
clModels <- list()
for(i in 0:5){
toTs <- custDict %>%
filter(cluster == i) %>%
left_join(data) %>%
group_by(date = cut(as.Date(date) ,'week')) %>%
summarise(sales = sum(sales), count_clients = n_distinct(customer) )%>%
mutate(avgSales = sales/count_clients )%>%
filter(as.Date(date) < as.Date('2017-12-01'))
clTs <- xts(toTs$avgSales,as.Date(toTs$date))
fit <- auto.arima(clTs)
print(i)
print(fit)
clModels[[i+1]] <- fit
}
return(clModels)
}
mods <- ModelsByClst(custDict,data)
ForDecSls <- function(custDict){
CustList <- list()
SlsList <- list()
compData <- data.frame(customer = integer(), sales= integer())
for (i in 1:length(custDict$customer)){
nCustomer <- custDict$customer[i]
nCluster <- custDict$cluster[i] +1
toTs <- data %>%
filter(customer == nCustomer) %>%
group_by(date) %>%
summarise(sales=sum(sales))
toTs$date<-as.Date(as.character(toTs$date))
toTs <- left_join(dictDates,toTs)
toTs$sales <- ifelse(is.na(toTs$sales),0,toTs$sales)
toTs <- toTs %>%
group_by(date = cut(as.Date(date) ,'week')) %>%
summarise(sales = sum(sales))%>%
filter(as.Date(date) < as.Date('2017-12-01'))
clTs <- xts(toTs$sales,as.Date(toTs$date))
fit<-Arima(clTs,model = mods[[nCluster]])
forSales<-forecast(fit, h=4)
slsDec <- sum(forSales[4]$mean[1:4])
compData <- rbind(compData,c(nCustomer, slsDec))
}
colnames(compData) <- c('Customer','SlsDecember')
return(compData)
}
DecemberSls <- ForDecSls(custDict)
